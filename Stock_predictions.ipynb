{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Stock_predictions.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shravs2523/Deep_learning/blob/master/Stock_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qTK4Ajv3qRz",
        "colab_type": "text"
      },
      "source": [
        "In this Colab, we will use a keras Long Short-Term Memory (LSTM) model to predict the stock price of Tata Global Beverages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs-XEsB86weU",
        "colab_type": "text"
      },
      "source": [
        "Here are some imports we need to make: numpy for scientific computation, matplotlib for graphing, and pandas for manipulating data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SoQJk5BYOas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD3hdApP7gNi",
        "colab_type": "text"
      },
      "source": [
        "Load training data set with the \"Open\" and \"High\" columns to use in our modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU6ve06iDV5Q",
        "colab_type": "code",
        "outputId": "f1d561cc-e02b-4f3c-ae6e-fc190dfab935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/mwitiderrick/stockprice/master/NSE-TATAGLOBAL.csv'\n",
        "dataset_train = pd.read_csv(url)\n",
        "print(dataset_train.shape)\n",
        "training_set = dataset_train.iloc[:, 1:2].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2035, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsLbMJ1072EY",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the first five rows of our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqiQMcfCLh6K",
        "colab_type": "code",
        "outputId": "9651bfd6-3fb2-4d06-a220-b029bd3497cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Last</th>\n",
              "      <th>Close</th>\n",
              "      <th>Total Trade Quantity</th>\n",
              "      <th>Turnover (Lacs)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-09-28</td>\n",
              "      <td>234.05</td>\n",
              "      <td>235.95</td>\n",
              "      <td>230.20</td>\n",
              "      <td>233.50</td>\n",
              "      <td>233.75</td>\n",
              "      <td>3069914</td>\n",
              "      <td>7162.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-09-27</td>\n",
              "      <td>234.55</td>\n",
              "      <td>236.80</td>\n",
              "      <td>231.10</td>\n",
              "      <td>233.80</td>\n",
              "      <td>233.25</td>\n",
              "      <td>5082859</td>\n",
              "      <td>11859.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-09-26</td>\n",
              "      <td>240.00</td>\n",
              "      <td>240.00</td>\n",
              "      <td>232.50</td>\n",
              "      <td>235.00</td>\n",
              "      <td>234.25</td>\n",
              "      <td>2240909</td>\n",
              "      <td>5248.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-09-25</td>\n",
              "      <td>233.30</td>\n",
              "      <td>236.75</td>\n",
              "      <td>232.00</td>\n",
              "      <td>236.25</td>\n",
              "      <td>236.10</td>\n",
              "      <td>2349368</td>\n",
              "      <td>5503.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-09-24</td>\n",
              "      <td>233.55</td>\n",
              "      <td>239.20</td>\n",
              "      <td>230.75</td>\n",
              "      <td>234.00</td>\n",
              "      <td>233.30</td>\n",
              "      <td>3423509</td>\n",
              "      <td>7999.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date    Open    High  ...   Close  Total Trade Quantity  Turnover (Lacs)\n",
              "0  2018-09-28  234.05  235.95  ...  233.75               3069914          7162.35\n",
              "1  2018-09-27  234.55  236.80  ...  233.25               5082859         11859.95\n",
              "2  2018-09-26  240.00  240.00  ...  234.25               2240909          5248.60\n",
              "3  2018-09-25  233.30  236.75  ...  236.10               2349368          5503.90\n",
              "4  2018-09-24  233.55  239.20  ...  233.30               3423509          7999.55\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWRZvVxcdhNa",
        "colab_type": "code",
        "outputId": "5d39853d-8fdb-44b0-9298-93bd2f6cd944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "training_set"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[234.05],\n",
              "       [234.55],\n",
              "       [240.  ],\n",
              "       ...,\n",
              "       [121.8 ],\n",
              "       [120.3 ],\n",
              "       [122.1 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii6nZaDI7-20",
        "colab_type": "text"
      },
      "source": [
        "Import MinMaxScaler from scikit-learn to scale our dataset into numbers between 0 and 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub32hsA4MIXz",
        "colab_type": "code",
        "outputId": "65187370-7170-4a95-bc3f-f17cf16265a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_set_scaled = sc.fit_transform(training_set)\n",
        "print(training_set_scaled)\n",
        "print(training_set_scaled.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6202352 ]\n",
            " [0.62226277]\n",
            " [0.64436334]\n",
            " ...\n",
            " [0.16504461]\n",
            " [0.15896188]\n",
            " [0.16626115]]\n",
            "(2035, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqze-4Is8Rb_",
        "colab_type": "text"
      },
      "source": [
        "We want our data to be in the form of a 3D array for our LSTM model. First, we create data in 60 timesteps and convert it into an array using NumPy. Then, we convert the data into a 3D array with X_train samples, 60 timestamps, and one feature at each step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo7K06T2Mi_e",
        "colab_type": "code",
        "outputId": "080c0f9f-a6a0-4395-abbf-5b14e1d3dc24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, 2035):\n",
        "    X_train.append(training_set_scaled[i-60:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])\n",
        "    #len(y_train)\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "print(X_train.shape)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "#print(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1975, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anIlTzKO-r74",
        "colab_type": "text"
      },
      "source": [
        "Make the necessary imports from keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP9GVtb9Q-C9",
        "colab_type": "code",
        "outputId": "2e70a1d2-3e0d-45fe-9862-f309d5273b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJrFWnOd-x2t",
        "colab_type": "text"
      },
      "source": [
        "Add LSTM layer along with dropout layers to prevent overfitting. After that, we add a Dense layer that specifies a one unit output. Next, we compile the model using the adam optimizer and set the loss as the mean_squarred_error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMKVOwBnRcOc",
        "colab_type": "code",
        "outputId": "5b7ce82f-1514-4693-d8c3-60583d7eb737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units=50,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units=50,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train,y_train,epochs=100,batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1975/1975 [==============================] - 14s 7ms/step - loss: 0.0125\n",
            "Epoch 2/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0027\n",
            "Epoch 3/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0028\n",
            "Epoch 4/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0025\n",
            "Epoch 5/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0025\n",
            "Epoch 6/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0020\n",
            "Epoch 7/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0023\n",
            "Epoch 8/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0020\n",
            "Epoch 9/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0021\n",
            "Epoch 10/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0021\n",
            "Epoch 11/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0019\n",
            "Epoch 12/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0017\n",
            "Epoch 13/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0019\n",
            "Epoch 14/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0016\n",
            "Epoch 15/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0017\n",
            "Epoch 16/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0016\n",
            "Epoch 17/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0015\n",
            "Epoch 18/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0016\n",
            "Epoch 19/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0013\n",
            "Epoch 20/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0013\n",
            "Epoch 21/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0013\n",
            "Epoch 22/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0013\n",
            "Epoch 23/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0013\n",
            "Epoch 24/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0014\n",
            "Epoch 25/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0013\n",
            "Epoch 26/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0011\n",
            "Epoch 27/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0010\n",
            "Epoch 28/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0013\n",
            "Epoch 29/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0011\n",
            "Epoch 30/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0011\n",
            "Epoch 31/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0012\n",
            "Epoch 32/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0011\n",
            "Epoch 33/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0010\n",
            "Epoch 34/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0011\n",
            "Epoch 35/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0012\n",
            "Epoch 36/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0011\n",
            "Epoch 37/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 9.4172e-04\n",
            "Epoch 38/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0011\n",
            "Epoch 39/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0011\n",
            "Epoch 40/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.8506e-04\n",
            "Epoch 41/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 9.4434e-04\n",
            "Epoch 42/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 9.4330e-04\n",
            "Epoch 43/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.4196e-04\n",
            "Epoch 44/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.8533e-04\n",
            "Epoch 45/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0010\n",
            "Epoch 46/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.6225e-04\n",
            "Epoch 47/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 9.2793e-04\n",
            "Epoch 48/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 9.1358e-04\n",
            "Epoch 49/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 0.0011\n",
            "Epoch 50/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.7576e-04\n",
            "Epoch 51/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.6704e-04\n",
            "Epoch 52/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 9.2051e-04\n",
            "Epoch 53/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.9329e-04\n",
            "Epoch 54/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 9.4121e-04\n",
            "Epoch 55/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.7817e-04\n",
            "Epoch 56/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.4139e-04\n",
            "Epoch 57/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.1033e-04\n",
            "Epoch 58/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.0355e-04\n",
            "Epoch 59/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.4576e-04\n",
            "Epoch 60/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.1440e-04\n",
            "Epoch 61/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.8476e-04\n",
            "Epoch 62/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.5904e-04\n",
            "Epoch 63/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.5041e-04\n",
            "Epoch 64/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.7514e-04\n",
            "Epoch 65/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.8477e-04\n",
            "Epoch 66/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.8581e-04\n",
            "Epoch 67/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.9808e-04\n",
            "Epoch 68/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.4231e-04\n",
            "Epoch 69/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.3815e-04\n",
            "Epoch 70/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.5088e-04\n",
            "Epoch 71/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.6595e-04\n",
            "Epoch 72/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.8158e-04\n",
            "Epoch 73/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.9326e-04\n",
            "Epoch 74/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.1146e-04\n",
            "Epoch 75/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 8.2408e-04\n",
            "Epoch 76/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.1598e-04\n",
            "Epoch 77/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.7292e-04\n",
            "Epoch 78/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.3166e-04\n",
            "Epoch 79/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.6574e-04\n",
            "Epoch 80/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 5.9884e-04\n",
            "Epoch 81/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.7396e-04\n",
            "Epoch 82/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.5380e-04\n",
            "Epoch 83/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.2883e-04\n",
            "Epoch 84/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.2691e-04\n",
            "Epoch 85/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 5.9080e-04\n",
            "Epoch 86/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.7583e-04\n",
            "Epoch 87/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.5465e-04\n",
            "Epoch 88/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.5492e-04\n",
            "Epoch 89/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.9258e-04\n",
            "Epoch 90/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.3892e-04\n",
            "Epoch 91/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.2079e-04\n",
            "Epoch 92/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.7082e-04\n",
            "Epoch 93/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.1875e-04\n",
            "Epoch 94/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 5.9223e-04\n",
            "Epoch 95/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 7.0015e-04\n",
            "Epoch 96/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.2947e-04\n",
            "Epoch 97/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.6464e-04\n",
            "Epoch 98/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.4328e-04\n",
            "Epoch 99/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 5.8845e-04\n",
            "Epoch 100/100\n",
            "1975/1975 [==============================] - 12s 6ms/step - loss: 6.9816e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a405eafd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7_w_7x-A44v",
        "colab_type": "text"
      },
      "source": [
        "Import the test set for the model to make predictions on "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns2TngWrUaz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/mwitiderrick/stockprice/master/tatatest.csv'\n",
        "dataset_test = pd.read_csv(url)\n",
        "real_stock_price = dataset_test.iloc[:, 1:2].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXGKvoo6BAyd",
        "colab_type": "text"
      },
      "source": [
        "Before predicting future stock prices, we have to manipulate the training set; we merge the training set and the test set on the 0 axis, set the time step to 60, use minmaxscaler, and reshape the dataset as done previously. After making predictions, we use inverse_transform to get back the stock prices in normal readable format.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBbdst_BV_PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
        "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs = sc.transform(inputs)\n",
        "X_test = []\n",
        "for i in range(60, 76):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predicted_stock_price = model.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAj_a3n0B3nz",
        "colab_type": "text"
      },
      "source": [
        "Plot our predicted stock prices and the actual stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czWvnIANYSqI",
        "colab_type": "code",
        "outputId": "7d4cb7e0-0ec3-4ed8-9194-bc85fa59e889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(real_stock_price, color = 'black', label = 'TATA Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'green', label = 'Predicted TATA Stock Price')\n",
        "plt.title('TATA Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('TATA Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFMzMrOCiYGZmBRcFMzMruCiYmVnh/y7kala1rdhKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}